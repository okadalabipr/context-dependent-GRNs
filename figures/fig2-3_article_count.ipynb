{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import ast\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from xml.etree import ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b90632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of publications related to the query using the PubMed API\n",
    "# The following process may take a long time\n",
    "def load_mesh_label():\n",
    "    df = pd.read_csv(\"../data/fig2-3/MeSH/mesh_disease_leaves_w_annotation.csv\")\n",
    "    mesh_id2name = dict(zip(df[\"mesh_id\"], df[\"label\"]))\n",
    "    return mesh_id2name\n",
    "\n",
    "def load_pmids_pubtator3():\n",
    "    chunk = 1\n",
    "    df = pd.read_parquet(f\"../data/fig2-3/All_MeSH_diseases_pmid_bert_corrs_chunk{chunk}.parquet\")\n",
    "    return df[\"pmid\"].astype(str).values\n",
    "\n",
    "\n",
    "def get_pubmed_counts(mesh_id, mesh_id2name, pmid2use):\n",
    "    sleep_time = random.uniform(0.5, 1.0)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    # Fist, get the total number of hits\n",
    "    query = mesh_id2name[mesh_id]\n",
    "    url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={query}&rettype=count\"\n",
    "    response = requests.get(url)\n",
    "    if not response.status_code == 200:\n",
    "        print(f\"[{mesh_id}] Error: {response.status_code}\")\n",
    "        return None\n",
    "    else:\n",
    "        root = ET.fromstring(response.text)\n",
    "        total_hits = int(root.find(\"Count\").text)\n",
    "\n",
    "        # Second, get the pmids\n",
    "        retmax = 100000\n",
    "        total_pmids = set()\n",
    "        for retstart in range(0, total_hits, retmax):\n",
    "            url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={query}&retstart={retstart}&retmax={retmax}\"\n",
    "            response = requests.get(url)\n",
    "            if not response.status_code == 200:\n",
    "                print(f\"[{mesh_id}] Error: {response.status_code}\")\n",
    "                return None\n",
    "            else:\n",
    "                root = ET.fromstring(response.text)\n",
    "                pmids = [id_elem.text for id_elem in root.findall(\".//Id\")]\n",
    "                total_pmids.update(set(pmids))\n",
    "        \n",
    "        # Third, get the intersection with the pmids2use\n",
    "        count = len(set(pmid2use.astype(str)) & total_pmids)\n",
    "        return count\n",
    "\n",
    "RE_CALCULATION = False\n",
    "if RE_CALCULATION:\n",
    "    mesh_id2name = load_mesh_label()\n",
    "    pmid2use = load_pmids_pubtator3()\n",
    "\n",
    "    pubmed_api_counts = []\n",
    "    for mesh_id in tqdm(mesh_id2name.keys()):\n",
    "        count = get_pubmed_counts(mesh_id)\n",
    "        pubmed_api_counts.append(count)\n",
    "\n",
    "    pubmed_api_counts = [int(x) for x in pubmed_api_counts if x is not None]\n",
    "    pubmed_api_counts = np.array(pubmed_api_counts)\n",
    "    np.save(\"../data/fig2-3/pubmed_api_counts.npy\", pubmed_api_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9756db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== CONFIGURATION ====================\n",
    "def configure_plot_style():\n",
    "    custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "    sns.set_theme(style=\"ticks\", rc=custom_params)\n",
    "    mpl.rcParams.update({\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 13,\n",
    "        'axes.labelsize': 16,\n",
    "        'axes.titlesize': 16,\n",
    "        'lines.linewidth': 1.5\n",
    "    })\n",
    "\n",
    "\n",
    "# ==================== DATA LOADING ====================\n",
    "def load_pmids():\n",
    "    df = pd.read_csv(\"../data/fig2-3/PubTator3/Pubtator3_BioREX_pmid_mesh.csv\")\n",
    "    df[\"from_mesh\"] = df[\"from_mesh\"].apply(ast.literal_eval)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_similarity_scores(num_chunks=3):\n",
    "    all_chunks = []\n",
    "    for chunk in range(1, num_chunks + 1):\n",
    "        df = pd.read_parquet(f\"../data/fig2-3/All_MeSH_diseases_pmid_bert_corrs_chunk{chunk}.parquet\")\n",
    "        if chunk == 1:\n",
    "            all_chunks.append(df[[\"pmid\"]])\n",
    "        all_chunks.append(df.drop(columns=[\"pmid\"], errors='ignore'))\n",
    "        del df\n",
    "        gc.collect()\n",
    "    return pd.concat(all_chunks, axis=1)\n",
    "\n",
    "\n",
    "def load_mesh_categories():\n",
    "    df = pd.read_csv(\"../data/fig2-3/MeSH/mesh_disease_leaves_w_annotation.csv\")\n",
    "    if isinstance(df[\"tree_categories\"].iloc[0], str):\n",
    "        df[\"tree_categories\"] = df[\"tree_categories\"].apply(ast.literal_eval)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_category_mapping():\n",
    "    df = pd.read_csv(\"../data/fig2-3/MeSH/MeSH_large_categories.csv\")\n",
    "    return dict(zip(df[\"mesh_id\"], df[\"name\"]))\n",
    "\n",
    "\n",
    "# ==================== PROCESSING ====================\n",
    "def create_mesh_one_hot(pmids_df, mesh2use):\n",
    "    mesh2idx = {mesh: idx for idx, mesh in enumerate(mesh2use)}\n",
    "    mesh_oh = np.zeros((len(pmids_df), len(mesh2use)), dtype=int)\n",
    "\n",
    "    for idx, row in tqdm(pmids_df.iterrows(), total=len(pmids_df)):\n",
    "        for mesh in row[\"from_mesh\"]:\n",
    "            if mesh.startswith(\"MESH:\"):\n",
    "                mesh = mesh.split(\":\")[1]\n",
    "                if mesh in mesh2idx:\n",
    "                    mesh_oh[idx, mesh2idx[mesh]] = 1\n",
    "    return mesh_oh\n",
    "\n",
    "\n",
    "def compute_correlations(pmid_corrs, mesh_oh, mesh2use):\n",
    "    corrs_pos, corrs_neg, mesh_ids = [], [], []\n",
    "\n",
    "    for i, mesh_id in enumerate(tqdm(mesh2use)):\n",
    "        if mesh_oh[:, i].sum() > 0:\n",
    "            pos_idx = np.where(mesh_oh[:, i] == 1)[0]\n",
    "            neg_idx = np.random.choice(np.where(mesh_oh[:, i] == 0)[0], len(pos_idx), replace=False)\n",
    "            corrs_pos.extend(pmid_corrs.loc[pos_idx, mesh_id].values)\n",
    "            corrs_neg.extend(pmid_corrs.loc[neg_idx, mesh_id].values)\n",
    "            mesh_ids.extend([mesh_id] * len(pos_idx))\n",
    "    return np.array(corrs_pos), np.array(corrs_neg), np.array(mesh_ids)\n",
    "\n",
    "\n",
    "# ==================== PUBMED API ====================\n",
    "def get_pubmed_counts(mesh_id, mesh_id2name, pmid2use):\n",
    "    time.sleep(random.uniform(0.5, 1.0))\n",
    "    query = mesh_id2name.get(mesh_id, \"\")\n",
    "    if not query:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={query}&rettype=count\"\n",
    "        response = requests.get(url)\n",
    "        root = ET.fromstring(response.text)\n",
    "        total_hits = int(root.find(\"Count\").text)\n",
    "\n",
    "        total_pmids = set()\n",
    "        retmax = 100000\n",
    "        for retstart in range(0, total_hits, retmax):\n",
    "            url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={query}&retstart={retstart}&retmax={retmax}\"\n",
    "            response = requests.get(url)\n",
    "            root = ET.fromstring(response.text)\n",
    "            pmids = [id_elem.text for id_elem in root.findall(\".//Id\")]\n",
    "            total_pmids.update(set(pmids))\n",
    "\n",
    "        count = len(set(pmid2use.astype(str)) & total_pmids)\n",
    "        return count\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {mesh_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_pubmed_counts(mesh2use, mesh_id2name, pmid2use, save_path):\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Loading cached PubMed counts from: {save_path}\")\n",
    "        return np.load(save_path)\n",
    "    \n",
    "    print(\"Fetching PubMed counts via API...\")\n",
    "    counts = []\n",
    "    for mesh_id in tqdm(mesh2use):\n",
    "        count = get_pubmed_counts(mesh_id, mesh_id2name, pmid2use)\n",
    "        counts.append(count)\n",
    "\n",
    "    counts = [int(x) for x in counts if x is not None]\n",
    "    np.save(save_path, counts)\n",
    "    print(f\"Saved PubMed counts to: {save_path}\")\n",
    "    return np.array(counts)\n",
    "\n",
    "\n",
    "# ==================== PLOTTING ====================\n",
    "def plot_article_count_comparison(mesh_tag_counts, pubmed_counts, bert_counts, output_path):\n",
    "    plt_df = pd.DataFrame({\n",
    "        \"count\": np.concatenate([mesh_tag_counts, pubmed_counts, bert_counts]),\n",
    "        \"type\": [\"MeSH-tag\"] * len(mesh_tag_counts) + [\"PubMed-API\"] * len(pubmed_counts) + [\"BERT-based\"] * len(bert_counts)\n",
    "    })\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 6))\n",
    "    sns.boxplot(data=plt_df, x=\"type\", y=\"count\", palette=[\"gray\", \"green\", \"red\"], ax=ax, width=0.5)\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Number of detected articles\")\n",
    "    ax.grid(True, axis=\"y\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(output_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== MAIN ====================\n",
    "configure_plot_style()\n",
    "\n",
    "pmids_df = load_pmids()\n",
    "sim_df = load_similarity_scores()\n",
    "mesh_category_df = load_mesh_categories()\n",
    "\n",
    "mesh2use = sim_df.columns[1:]\n",
    "pmid2use = sim_df[\"pmid\"].values\n",
    "pmids_df = pmids_df.set_index(\"pmid\").loc[pmid2use].reset_index()\n",
    "\n",
    "mesh_oh = create_mesh_one_hot(pmids_df, mesh2use)\n",
    "\n",
    "# Mapping\n",
    "mesh_id2name = dict(zip(mesh_category_df[\"mesh_id\"], mesh_category_df[\"label\"]))\n",
    "all_categories = sorted(set(itertools.chain(*mesh_category_df[\"tree_categories\"].values)) - {\"C22\"})\n",
    "cat2mesh = {\n",
    "    cat: mesh_category_df[mesh_category_df[\"tree_categories\"].apply(lambda x: cat in x)][\"mesh_id\"].values\n",
    "    for cat in all_categories\n",
    "}\n",
    "\n",
    "# Visualization\n",
    "plot_article_count_comparison(\n",
    "    mesh_tag_counts=mesh_oh.sum(axis=0),\n",
    "    pubmed_counts=fetch_pubmed_counts(mesh2use, mesh_id2name, pmid2use, \"../data/fig2-3/all_mesh_pubmed_api_counts.npy\"),\n",
    "    bert_counts=(sim_df.iloc[:, 1:].values > 0.2).sum(axis=0),\n",
    "    output_path=\"../data/fig2-3/fig2.all_mesh_number_of_detected_articles.png\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
