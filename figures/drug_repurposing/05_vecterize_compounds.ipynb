{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique drugs: 2074\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Load the data\n",
    "####################\n",
    "# 1. Drug-disease dataframe\n",
    "files = [\"complex_disease_train_w_name.csv\", \"complex_disease_test_w_name.csv\", \"complex_disease_valid_w_name.csv\"]\n",
    "df = pd.concat([pd.read_csv(f) for f in files]).reset_index(drop=True)\n",
    "\n",
    "# 2. Retrieve drug names\n",
    "drug_id2name = {}\n",
    "for _, row in df.iterrows():\n",
    "    if row[\"x_type\"] == \"drug\":\n",
    "        drug_id2name[row[\"x_id\"]] = row[\"x_name\"]\n",
    "    if row[\"y_type\"] == \"drug\":\n",
    "        drug_id2name[row[\"y_id\"]] = row[\"y_name\"]\n",
    "print(f\"Number of unique drugs: {len(drug_id2name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Retrieve drug-reporeted pmids\n",
    "import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_pubmed_ids(query, db=\"pubmed\"):\n",
    "    sleep_time = random.uniform(0.5, 1.0)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db={db}&term={query}&rettype=count\"\n",
    "    response = requests.get(url)\n",
    "    if not response.status_code == 200:\n",
    "        print(f\"[{query}] Error: {response.status_code}\")\n",
    "        return None\n",
    "    else:\n",
    "        root = ET.fromstring(response.text)\n",
    "        total_hits = int(root.find(\"Count\").text)\n",
    "\n",
    "        # Second, get the pmids\n",
    "        retmax = 100000\n",
    "        total_pmids = set()\n",
    "        for retstart in range(0, total_hits, retmax):\n",
    "            url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db={db}&term={query}&retstart={retstart}&retmax={retmax}\"\n",
    "            response = requests.get(url)\n",
    "            if not response.status_code == 200:\n",
    "                print(f\"[{query}] Error: {response.status_code}\")\n",
    "                return None\n",
    "            else:\n",
    "                root = ET.fromstring(response.text)\n",
    "                pmids = [id_elem.text for id_elem in root.findall(\".//Id\")]\n",
    "                total_pmids.update(set(pmids))\n",
    "        \n",
    "        import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "import random\n",
    "import time\n",
    "\n",
    "def get_pubmed_ids(query, db=\"pubmed\"):\n",
    "    sleep_time = random.uniform(0.5, 1.0)\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db={db}&term={query}&rettype=count\"\n",
    "    response = requests.get(url)\n",
    "    if not response.status_code == 200:\n",
    "        print(f\"[{query}] Error: {response.status_code}\")\n",
    "        return None\n",
    "    else:\n",
    "        root = ET.fromstring(response.text)\n",
    "        total_hits = int(root.find(\"Count\").text)\n",
    "\n",
    "        # Second, get the pmids\n",
    "        retmax = 100000\n",
    "        total_pmids = set()\n",
    "        for retstart in range(0, total_hits, retmax):\n",
    "            url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db={db}&term={query}&retstart={retstart}&retmax={retmax}\"\n",
    "            response = requests.get(url)\n",
    "            if not response.status_code == 200:\n",
    "                print(f\"[{query}] Error: {response.status_code}\")\n",
    "                return None\n",
    "            else:\n",
    "                root = ET.fromstring(response.text)\n",
    "                pmids = [id_elem.text for id_elem in root.findall(\".//Id\")]\n",
    "                total_pmids.update(set(pmids))\n",
    "        \n",
    "        total_pmids = sorted(list(total_pmids))\n",
    "        return total_pmids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2074/2074 [1:28:26<00:00,  2.56s/it]  \n"
     ]
    }
   ],
   "source": [
    "drug_pmids = [(drug_id, get_pubmed_ids(drug_name)) for drug_id, drug_name in tqdm(drug_id2name.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 2002/2074 [1:17:52<02:46,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Albutrepenonacog alfa] Error: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2074/2074 [1:20:36<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "drug_pmids_pmc = [(drug_id, get_pubmed_ids(drug_name, db=\"pmc\")) for drug_id, drug_name in tqdm(drug_id2name.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"05_drug_pmids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(drug_pmids, f)\n",
    "\n",
    "with open(\"05_drug_pmids_pmc.pkl\", \"wb\") as f:\n",
    "    pickle.dump(drug_pmids_pmc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique PMC IDs: 6492520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32463/32463 [1:06:48<00:00,  8.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert PMC to PMID\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import random\n",
    "\n",
    "def pmc2pmid(pmc_ids: list):\n",
    "    # random sleep\n",
    "    sleep_time = random.uniform(0.5, 1.0)\n",
    "\n",
    "    base_url = 'https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/'\n",
    "    params = {\n",
    "        \"ids\": \",\".join([\"PMC\" + pmc_id for pmc_id in pmc_ids]),\n",
    "        \"tool\": \"MyPMCApp\",\n",
    "        \"email\": \"masato.tsutsui@protein.osaka-u.ac.jp\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if not response.status_code == 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "    else:\n",
    "        data = response.json()\n",
    "\n",
    "        mapping = {}\n",
    "        for record in data.get(\"records\", []):\n",
    "            pmcid = record.get(\"pmcid\")\n",
    "            pmid = record.get(\"pmid\")\n",
    "            mapping[pmcid] = pmid\n",
    "        return mapping\n",
    "\n",
    "all_pmc_ids = set()\n",
    "for _, pmc_ids in drug_pmids_pmc:\n",
    "    if pmc_ids is not None:\n",
    "        all_pmc_ids.update(pmc_ids)\n",
    "all_pmc_ids = list(all_pmc_ids)\n",
    "print(f\"Number of unique PMC IDs: {len(all_pmc_ids)}\")\n",
    "\n",
    "bs = 200\n",
    "pmc2pmid_parallel = Parallel(n_jobs=5)(delayed(pmc2pmid)(all_pmc_ids[i:i+bs]) for i in tqdm(range(0, len(all_pmc_ids), bs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmc2pmid = {}\n",
    "for mapping in pmc2pmid_parallel:\n",
    "    if mapping is not None:\n",
    "        mapping = {k.replace(\"PMC\", \"\"): v for k, v in mapping.items()}\n",
    "        pmc2pmid.update(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug2pmids= {}\n",
    "for drug, pmids in drug_pmids:\n",
    "    if pmids is not None:\n",
    "        drug2pmids[drug] = pmids.copy()\n",
    "    else:\n",
    "        drug2pmids[drug] = []\n",
    "\n",
    "for drug, pmc_ids in drug_pmids_pmc:\n",
    "    if pmc_ids is not None:\n",
    "        pmids = [pmc2pmid[pmc_id] for pmc_id in pmc_ids if pmc2pmid[pmc_id] is not None]\n",
    "        drug2pmids[drug].extend(pmids)\n",
    "    else:\n",
    "        drug2pmids[drug].extend([])\n",
    "\n",
    "drug2pmids = {drug: sorted(list(set(pmids))) for drug, pmids in drug2pmids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug, pmids in drug2pmids.items():\n",
    "    if len(pmids) == 0:\n",
    "        print(f\"{drug} has no pmids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_pmids = sorted(list({pmid for pmids in drug2pmids.values() for pmid in pmids}))\n",
    "\n",
    "pmids2drug = {pmid: [] for pmid in detected_pmids}\n",
    "for drug, pmids in drug2pmids.items():\n",
    "    for pmid in pmids:\n",
    "        pmids2drug[pmid].append(drug)\n",
    "\n",
    "with open(\"05_drugbank_pmids.txt\", \"w\") as f:\n",
    "    for pmid, drugs in pmids2drug.items():\n",
    "        f.write(f\"{pmid}\\t{','.join(drugs)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "drug_id2pmid_counts = Counter()\n",
    "\n",
    "with open(\"05_drugbank_pmids.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        pmid, drugs = line.strip().split(\"\\t\")\n",
    "        drugs = drugs.split(\",\")\n",
    "        drug_id2pmid_counts.update(drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Merge the pmid-drug information with Pubtator3\n",
    "#####################################\n",
    "from scipy.sparse import lil_matrix\n",
    "pubtator3_dir = \"/share/pubtator3\"\n",
    "\n",
    "# Define the matrix\n",
    "num_pmids = len(pmids2drug)\n",
    "num_drugs = len(drug_id2name)\n",
    "drug_oh = lil_matrix((num_pmids, num_drugs), dtype=int)\n",
    "\n",
    "drug2idx = {}\n",
    "drug_ids_to_use = []\n",
    "drug_names_to_use = []\n",
    "for i, (drug_id, drug_name) in enumerate(drug_id2name.items()):\n",
    "    drug2idx[drug_id] = i\n",
    "    drug_names_to_use.append(drug_name)\n",
    "    drug_ids_to_use.append(drug_id)\n",
    "\n",
    "# Get indices for pmids in pubtator3\n",
    "indices = []\n",
    "j = 0\n",
    "\n",
    "with open(os.path.join(pubtator3_dir, \"count_data\", \"pubtator3_pmids.txt\")) as f:\n",
    "    for i, pmid in enumerate(f.read().splitlines()):\n",
    "        if pmid in pmids2drug:\n",
    "            indices.append(i)\n",
    "            # Update the drug one-hot matrix\n",
    "            for drug in pmids2drug[pmid]:\n",
    "                drug_oh[j, drug2idx[drug]] = 1\n",
    "            j += 1\n",
    "\n",
    "drug_oh = drug_oh.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_mtx: (30338029, 11736685)\n",
      "genes for analysis: 190337\n",
      "genes for analysis (unique): 154839\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "### Load Pubtator3 counts\n",
    "#########################\n",
    "from scipy.io import mmread\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "count_mtx = mmread(os.path.join(pubtator3_dir, \"count_data\", \"counts.mtx\"))\n",
    "print(\"count_mtx:\", count_mtx.shape)\n",
    "\n",
    "# All human entrez gene ids\n",
    "all_human_entrez = set(pd.read_csv(os.path.join(pubtator3_dir, \"data\", \"input\", \"all_human_entrez.csv\"))[\"ENTREZID\"].astype(str))\n",
    "\n",
    "# Obtrain the indice of GeneID\n",
    "gene_ind = []\n",
    "gene_ids = []\n",
    "\n",
    "with open(os.path.join(pubtator3_dir, \"count_data\", \"vocab.txt\")) as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"Gene\"):\n",
    "            # Take only the first GeneID into account e.g. 'Gene|100000688;571349;327429' --> 'Gene|100000688'\n",
    "            # Because of this procedure, the vocabs become overlapped.\n",
    "            line = line.split(\";\")[0]\n",
    "            line = line.replace(\"Gene|\", \"\")\n",
    "            if line in all_human_entrez:\n",
    "                gene_ind.append(i)\n",
    "                gene_ids.append(line)\n",
    "\n",
    "gene_ind = np.array(gene_ind)\n",
    "gene_ids = np.array(gene_ids)\n",
    "\n",
    "print(\"genes for analysis:\", len(gene_ids))\n",
    "print(\"genes for analysis (unique):\", len(np.unique(gene_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analysis will target 3,485,523 documents.\n"
     ]
    }
   ],
   "source": [
    "counts2use_gene_related = count_mtx.tocsr()[indices, :][:, gene_ind].copy()\n",
    "counts2use_cpd_related = drug_oh[:len(indices), :].copy()\n",
    "\n",
    "rows_to_use = np.where(counts2use_gene_related.sum(axis=1)>0)[0]\n",
    "counts2use_gene_related = counts2use_gene_related[rows_to_use]\n",
    "counts2use_cpd_related = counts2use_cpd_related[rows_to_use]\n",
    "print(f\"The analysis will target {len(rows_to_use):,} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts2use_gene_related_aggregated: (3485523, 154839)\n",
      "cpd_gene_co_occurrence: (2074, 154839)\n"
     ]
    }
   ],
   "source": [
    "# First, aggregate counts using indice with same GeneID\n",
    "from scipy.sparse import coo_matrix\n",
    "unique_genes, indices = np.unique(gene_ids, return_inverse=True)\n",
    "\n",
    "coo = coo_matrix(counts2use_gene_related)\n",
    "\n",
    "row = coo.row\n",
    "col = indices[coo.col]\n",
    "data = coo.data\n",
    "\n",
    "counts2use_gene_related_aggregated = coo_matrix((data, (row, col)), shape=(coo.shape[0], len(unique_genes))).tocsr()\n",
    "\n",
    "# Convert elements: if greater than 0, set to 1; otherwise, set to 0\n",
    "counts2use_gene_related_aggregated = (counts2use_gene_related_aggregated > 0).astype(int)\n",
    "print(\"counts2use_gene_related_aggregated:\", counts2use_gene_related_aggregated.shape)\n",
    "\n",
    "\n",
    "# co-occurrence matrix\n",
    "cpd_gene_co_occurrence = counts2use_cpd_related.T.dot(counts2use_gene_related_aggregated)\n",
    "print(\"cpd_gene_co_occurrence:\", cpd_gene_co_occurrence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "sp.save_npz(\"05_cpd_gene_co_occurrence.npz\", cpd_gene_co_occurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_id</th>\n",
       "      <th>drug_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>DB00030</td>\n",
       "      <td>Insulin human</td>\n",
       "      <td>7394498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>DB00133</td>\n",
       "      <td>Serine</td>\n",
       "      <td>6457136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>DB01082</td>\n",
       "      <td>Streptomycin</td>\n",
       "      <td>5275975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>DB00052</td>\n",
       "      <td>Somatotropin</td>\n",
       "      <td>5088948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>DB00123</td>\n",
       "      <td>L-Lysine</td>\n",
       "      <td>4136409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>DB13727</td>\n",
       "      <td>Azapetine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>DB13695</td>\n",
       "      <td>Penthienate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>DB14123</td>\n",
       "      <td>Racementhol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>DB13396</td>\n",
       "      <td>Neocitrullamon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>DB13788</td>\n",
       "      <td>Chlorbenzoxamine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2074 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      drug_id         drug_name    count\n",
       "1560  DB00030     Insulin human  7394498\n",
       "801   DB00133            Serine  6457136\n",
       "944   DB01082      Streptomycin  5275975\n",
       "1818  DB00052      Somatotropin  5088948\n",
       "949   DB00123          L-Lysine  4136409\n",
       "...       ...               ...      ...\n",
       "1666  DB13727         Azapetine        1\n",
       "1231  DB13695       Penthienate        1\n",
       "555   DB14123       Racementhol        1\n",
       "2034  DB13396    Neocitrullamon        0\n",
       "746   DB13788  Chlorbenzoxamine        0\n",
       "\n",
       "[2074 rows x 3 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurrence_counts = pd.DataFrame({\"drug_id\": drug_ids_to_use, \"drug_name\": drug_names_to_use,\n",
    "                                    \"count\": cpd_gene_co_occurrence.sum(axis=1).A1})\n",
    "cooccurrence_counts.sort_values(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "cpd_gene_co_occurrence = sp.load_npz(\"05_cpd_gene_co_occurrence.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/scipy/sparse/_base.py:713: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in divide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# normalize\n",
    "cpd_gene_co_occurrence = np.log1p(cpd_gene_co_occurrence / cpd_gene_co_occurrence.sum(axis=1) * 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 154839\n",
      "Number of features after removing low variance features: 27149\n",
      "Number of features after PCA: 200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def calc_cpd_features(cpd_gene_co_occurrence, threshold=0.01, n_components=200):\n",
    "    print(\"Original number of features:\", cpd_gene_co_occurrence.shape[1])\n",
    "    # 1. Log-transformed\n",
    "    # data = np.log1p(cpd_gene_co_occurrence)\n",
    "    data = cpd_gene_co_occurrence.copy()\n",
    "\n",
    "    # 2. Remove genes with low variance\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    data = selector.fit_transform(data)\n",
    "    print(\"Number of features after removing low variance features:\", data.shape[1])\n",
    "\n",
    "    # 3. Standardize\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data.A)\n",
    "\n",
    "    # 4. PCA\n",
    "    pca = PCA(n_components=n_components, random_state=0)\n",
    "    data = pca.fit_transform(data)\n",
    "    print(\"Number of features after PCA:\", data.shape[1])\n",
    "\n",
    "    return data\n",
    "\n",
    "cpd_features = calc_cpd_features(cpd_gene_co_occurrence, threshold=0.01, n_components=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(cpd_features, columns=[f\"PCA_{i}\" for i in range(cpd_features.shape[1])])\n",
    "feature_df.insert(0, \"drug_id\", drug_ids_to_use)\n",
    "feature_df.insert(1, \"drug_name\", drug_names_to_use)\n",
    "feature_df.to_csv(\"05_cpd_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
